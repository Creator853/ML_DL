{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titanic Dataset again !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the data and perform train_test_split\n",
    "df = pd.read_excel(\"titanic.xlsx\")\n",
    "df = df.drop(columns=[\"name\", \"cabin\", \"embarked\", \"boat\", \"body\", \"home.dest\", \"ticket\"])\n",
    "df = df.fillna(0)\n",
    "train, test =  train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived  sex      age  sibsp  parch      fare\n",
       "0       1         1    0  29.0000      0      0  211.3375\n",
       "1       1         1    1   0.9167      1      2  151.5500\n",
       "2       1         0    0   2.0000      1      2  151.5500\n",
       "3       1         0    1  30.0000      1      2  151.5500\n",
       "4       1         0    0  25.0000      1      2  151.5500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "#One thing to note here is that that 0 --> female 1 --> male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data \n",
      " Train:  (1047, 7)  \n",
      " Test:  (262, 7)\n"
     ]
    }
   ],
   "source": [
    "#Shape of train and test data\n",
    "print(\"Shape of data \\n Train: \", train.shape, \" \\n Test: \",test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separation of independent and dependent variables in tarin and test data \n",
    "train_x = train.drop(columns=[\"survived\"], axis=1)\n",
    "train_y = train[\"survived\"]\n",
    "test_x = test.drop(columns=[\"survived\"], axis=1)\n",
    "test_y = test[\"survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Object Initilisation and fitting of the model \n",
    "model = RandomForestClassifier()\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees used:  100\n"
     ]
    }
   ],
   "source": [
    "#Number of trees used \n",
    "print(\"Number of trees used: \", model.n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth =  18\n",
      "Depth =  18\n",
      "Depth =  18\n",
      "Depth =  17\n",
      "Depth =  19\n",
      "Depth =  18\n",
      "Depth =  16\n",
      "Depth =  19\n",
      "Depth =  20\n",
      "Depth =  21\n",
      "Depth =  22\n",
      "Depth =  18\n",
      "Depth =  19\n",
      "Depth =  18\n",
      "Depth =  20\n",
      "Depth =  19\n",
      "Depth =  19\n",
      "Depth =  20\n",
      "Depth =  16\n",
      "Depth =  17\n",
      "Depth =  17\n",
      "Depth =  20\n",
      "Depth =  20\n",
      "Depth =  21\n",
      "Depth =  20\n",
      "Depth =  19\n",
      "Depth =  19\n",
      "Depth =  16\n",
      "Depth =  19\n",
      "Depth =  19\n",
      "Depth =  17\n",
      "Depth =  22\n",
      "Depth =  20\n",
      "Depth =  17\n",
      "Depth =  18\n",
      "Depth =  18\n",
      "Depth =  25\n",
      "Depth =  19\n",
      "Depth =  17\n",
      "Depth =  18\n",
      "Depth =  20\n",
      "Depth =  15\n",
      "Depth =  17\n",
      "Depth =  17\n",
      "Depth =  22\n",
      "Depth =  19\n",
      "Depth =  17\n",
      "Depth =  17\n",
      "Depth =  17\n",
      "Depth =  19\n",
      "Depth =  17\n",
      "Depth =  18\n",
      "Depth =  17\n",
      "Depth =  20\n",
      "Depth =  19\n",
      "Depth =  18\n",
      "Depth =  20\n",
      "Depth =  22\n",
      "Depth =  19\n",
      "Depth =  18\n",
      "Depth =  20\n",
      "Depth =  15\n",
      "Depth =  20\n",
      "Depth =  21\n",
      "Depth =  16\n",
      "Depth =  21\n",
      "Depth =  23\n",
      "Depth =  17\n",
      "Depth =  22\n",
      "Depth =  18\n",
      "Depth =  18\n",
      "Depth =  20\n",
      "Depth =  20\n",
      "Depth =  17\n",
      "Depth =  15\n",
      "Depth =  18\n",
      "Depth =  18\n",
      "Depth =  18\n",
      "Depth =  17\n",
      "Depth =  22\n",
      "Depth =  18\n",
      "Depth =  18\n",
      "Depth =  19\n",
      "Depth =  18\n",
      "Depth =  19\n",
      "Depth =  19\n",
      "Depth =  17\n",
      "Depth =  17\n",
      "Depth =  18\n",
      "Depth =  21\n",
      "Depth =  19\n",
      "Depth =  18\n",
      "Depth =  21\n",
      "Depth =  17\n",
      "Depth =  18\n",
      "Depth =  17\n",
      "Depth =  19\n",
      "Depth =  22\n",
      "Depth =  20\n",
      "Depth =  22\n"
     ]
    }
   ],
   "source": [
    "#Now let's try to find out the depth of each tree in random forest\n",
    "for dtree in model:\n",
    "    print(\"Depth = \", dtree.get_depth())\n",
    "\n",
    "#Why did we do this ? Well just to get an idea of how much greenery is present in the forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on train:  [0 0 0 ... 1 0 0]\n",
      "Prediction on test:  [0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1\n",
      " 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0\n",
      " 1 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0\n",
      " 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "#Prediction on train and test dataset.\n",
    "print(\"Prediction on train: \", model.predict(train_x))\n",
    "print(\"Prediction on test: \", model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percent on train dataset:  97.23018147086916\n",
      "Accuracy percent on test dataset:  77.09923664122137\n"
     ]
    }
   ],
   "source": [
    "#Let's check accuracy score for train and test datasets\n",
    "print(\"Accuracy percent on train dataset: \", 100*accuracy_score(train_y, model.predict(train_x)))\n",
    "print(\"Accuracy percent on test dataset: \", 100*accuracy_score(test_y, model.predict(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well what we can see above is a clear case of overfitting.\n",
    "\n",
    "So now question is how do we resolve it ?\n",
    "\n",
    "Well there are many methods for it first and foremost it's the \"tuning of hyperparameters\"\n",
    "\n",
    "Let's try to tune the max_depth parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features used in model:  6\n"
     ]
    }
   ],
   "source": [
    "#Let's initilise a new RandomForest Object and try to tune some hyperparameters.\n",
    "model1 = RandomForestClassifier(min_samples_split=3, max_features = 4)\n",
    "model1.fit(train_x, train_y)\n",
    "print(\"Total number of features used in model: \", model1.n_features_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on train:  [0 0 0 ... 1 0 0]\n",
      "Prediction on test:  [0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1\n",
      " 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 1 0 0 0\n",
      " 1 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0\n",
      " 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1\n",
      " 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "#New predictions\n",
    "print(\"Prediction on train: \", model1.predict(train_x))\n",
    "print(\"Prediction on test: \", model1.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percent on train dataset:  96.4660936007641\n",
      "Accuracy percent on test dataset:  77.48091603053436\n"
     ]
    }
   ],
   "source": [
    "#New Metrics\n",
    "print(\"Accuracy percent on train dataset: \", 100*accuracy_score(train_y, model1.predict(train_x)))\n",
    "print(\"Accuracy percent on test dataset: \", 100*accuracy_score(test_y, model1.predict(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although I've just published the final version of my code ut I've tried to play with many hyperparameters and parameters beofre coming to this o/p and I could see that there hasn't been much improvement in the performance metrics for test data.\n",
    "\n",
    "Why ? Well I don't know that yet. Will try to figure out and repost this project with performance metrics improved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de40cebb529f8d7afb1b791fbae23bf4c4a133030df99b4a47ac4a5825bb4e1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
